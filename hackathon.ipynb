{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee3c866-d741-460d-b2a2-203093f3846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "\n",
    "# Create vector database\n",
    "class VectorStore:\n",
    "    \"\"\"Class to create VectorDB\"\"\"\n",
    "    def __init__(self, data_path, db_path):\n",
    "        \"\"\"\n",
    "        Initialize the variables for VectorStore.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.db_path = db_path\n",
    "        \n",
    "    def create_vector_db(self):\n",
    "        \"\"\"\n",
    "        function to build vector DB.\n",
    "        \"\"\"\n",
    "        DATA_PATH = self.data_path\n",
    "        DB_FAISS_PATH = self.db_path\n",
    "        loader_pdf = DirectoryLoader(DATA_PATH,\n",
    "                                 glob=f'*.pdf',\n",
    "                                 loader_cls=PyPDFLoader)\n",
    "\n",
    "        loader_text = DirectoryLoader(DATA_PATH,\n",
    "                                 glob=f'*.txt',\n",
    "                                 loader_cls=TextLoader)\n",
    "\n",
    "        documents_pdf = loader_pdf.load()\n",
    "        documents_text = loader_text.load()\n",
    "        documents = documents_pdf + documents_text\n",
    "        for i in documents:\n",
    "            i.page_content = i.page_content.replace(' . ','').replace('\\n',' ')\n",
    "            i.page_content = re.sub(r'\\.+', \".\", i.page_content)\n",
    "            i.page_content = ' '.join(i.page_content.split())\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                                       chunk_overlap=50)\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L12-v2',\n",
    "                                           model_kwargs={'device': 'cuda'})\n",
    "\n",
    "        db = FAISS.from_documents(texts, embeddings)\n",
    "        db.save_local(DB_FAISS_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = '/home/chirayu.tripathi/hackathon/'\n",
    "    db_path = '/home/chirayu.tripathi/hackathon/vectorstore/db_faiss'\n",
    "    obj = VectorStore(data_path, db_path)\n",
    "    obj.create_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5268776-52f3-49dc-8186-6aefe195a28d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chirayu.tripathi/venv/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:1020: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/chirayu.tripathi/venv/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c82a842a6114b1bb29cf94478c06b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chirayu.tripathi/venv/lib/python3.8/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/chirayu.tripathi/venv/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n",
      "2023-10-15 16:04:35 - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L12-v2\n",
      "Running on local URL:  http://127.0.0.1:7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://5bf6106a637dd6a0a3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5bf6106a637dd6a0a3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "import chainlit as cl\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "import gradio as gr\n",
    "\n",
    "class VerizonAI:\n",
    "    \"\"\" Class VerizonAI to create the chatbot object \"\"\"\n",
    "    def __init__(self, db_path):\n",
    "        \"\"\"\n",
    "        Initialize the class object.\n",
    "        \"\"\"\n",
    "        self.DB_FAISS_PATH = '/home/chirayu.tripathi/hackathon/vectorstore/db_faiss'\n",
    "\n",
    "        self.custom_prompt_template = \"\"\"[INST] You are a Verizon company's chatbot, Only use the following pieces of context to answer the user's question. If the answer is not present in context, just say that you don't know and display the following link \"https://www.verizon.com/support/residential/contact-us/contactuslanding.htm\", don't try to make up an answer.[/INST]\n",
    "\n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "        answer: \n",
    "        \"\"\"\n",
    "        self.generate_text = self.get_pipeline()\n",
    "        self.qa_result = self.qa_bot()\n",
    "        \n",
    "    def get_pipeline(self):\n",
    "        # model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "        model_id = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
    "        device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "        bnb_config = transformers.BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type='nf4',\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=bfloat16\n",
    "        )\n",
    "\n",
    "        hf_auth = '' #not required for mistral, but required for llama-2\n",
    "        model_config = transformers.AutoConfig.from_pretrained(\n",
    "            model_id,\n",
    "            use_auth_token=hf_auth\n",
    "        )\n",
    "\n",
    "        model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True,\n",
    "            config=model_config,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map='auto',\n",
    "            use_auth_token=hf_auth\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        model_id,\n",
    "        use_auth_token=hf_auth\n",
    "        )\n",
    "\n",
    "        print(f\"Model loaded on {device}\")\n",
    "\n",
    "        generate_text = transformers.pipeline(\n",
    "        model=model, \n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=True,  # langchain expects the full text\n",
    "        task='text-generation',\n",
    "        # we pass model parameters here too\n",
    "        # stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "        temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "        max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "        repetition_penalty=1.1  # without this output begins repeating\n",
    "        )\n",
    "        return generate_text\n",
    "    \n",
    "    def set_custom_prompt(self):\n",
    "        \"\"\"\n",
    "        Prompt template for QA retrieval for each vectorstore\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=self.custom_prompt_template,\n",
    "                                input_variables=['context', 'question'])\n",
    "        return prompt\n",
    "\n",
    "\n",
    "\n",
    "    def retrieval_qa_chain(self, llm, prompt, db):\n",
    "        \"\"\" Create the QA retrieval chain from langchain. \"\"\"\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                           chain_type='stuff',\n",
    "                                           retriever=db.as_retriever(search_kwargs={'k': 3}),#, search_type=\"mmr\"),\n",
    "                                           return_source_documents=True,\n",
    "                                           # memory = memory\n",
    "                                           chain_type_kwargs={'prompt': prompt}\n",
    "                                           )\n",
    "\n",
    "        return qa_chain\n",
    "    \n",
    "    def load_llm(self):\n",
    "        \"\"\" Load the model using the huggingface pipeline. \"\"\"\n",
    "        llm = HuggingFacePipeline(pipeline=self.generate_text)\n",
    "        return llm\n",
    "\n",
    "    \n",
    "    def qa_bot(self):\n",
    "        \"\"\"Setup the QA bot\"\"\"\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "                                           model_kwargs={'device': 'cuda'})\n",
    "        db = FAISS.load_local(self.DB_FAISS_PATH, embeddings)\n",
    "        llm = self.load_llm()\n",
    "        qa_prompt = self.set_custom_prompt()\n",
    "        qa = self.retrieval_qa_chain(llm, qa_prompt, db)\n",
    "\n",
    "        return qa\n",
    "\n",
    "    \n",
    "    def final_result(self,message,history):\n",
    "        \"\"\"Function to generate the result\"\"\"\n",
    "        response = self.qa_result({'query': message})\n",
    "        return response['result']\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    bot = VerizonAI(db_path = '/home/chirayu.tripathi/hackathon/vectorstore/db_faiss')\n",
    "    gr.ChatInterface(bot.final_result, title=\"VerAIzon Bot\").launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf6397c-b6c0-42d5-8610-8730bb055774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9631f017447d41dab8d0ab55552c750f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n",
      "2023-10-15 13:54:02 - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L12-v2\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "bot = VerizonAI(db_path = '/home/chirayu.tripathi/hackathon/vectorstore/db_faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f6bfb18-e74e-4839-bd6f-d101f513d066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d7bc7c081641acb60e9db7154e5652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. Call Home Voice Mail as described in “Accessing Your Mailbox.” \\n        2. Press 1 at the Main Menu to hear your messages. \\n        3. After you hear each message, you can:\\n            * Press 1 to replay the message.\\n            * Press 2 to save it.\\n            * Press 3 to erase it.\\n            * Press 4 to reply to a message left by another mailbox subscriber.\\n            * Press 5 to send a copy to another mailbox.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.final_result('What is the procedure to listen to my messages?','ff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bb154-f449-429e-80a4-95256aab904e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_result = qa_bot()\n",
    "response = qa_result({'query': 'What is the procedure to listen to my messages, provide in bullet points'})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "243d7946-ccc3-4c54-9f4d-95b2a6233e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-15 13:24:57 - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cd7b273f994dcb88d7423cea9bd5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what are the deals on iphones?',\n",
       " 'result': '\\nWe have several deals available on iPhones. One offer includes up to $999.99 device payment or full retail purchase with a new smartphone line on the Unlimited Ultimate plan required. With this offer, you can receive less up to $999.99 promo credit applied over 36 months; promo credit ends if eligibility requirements are no longer met; 0% APR. Another offer includes trading in your current device and saving $830 on the purchase of a new iPhone. Additionally, we have a deal where you can save on both the iPhone and Apple Watch when you buy them together. Please visit our website for more information on these offers and how to redeem them.',\n",
       " 'source_documents': [Document(page_content=\"offer.Up to $999.99 device payment or full retail purchase w/ new smartphone line on Unlimited Ultimate plan req'd. Less up to $999.99 promo credit applied over 36 mos.; promo credit ends if eligibility req’s are no longer met; 0% APR. end of navigation menu HomeSmartphonesAppleApple iPhone 15Starts at $23.05/mo$829.993.9 out of 5 rating495 ReviewsAvailable offersTrade in and save $830. New line req'd.Trade in and save $830. New line req'd. DetailsSave on Apple iPad and Apple Watch.Save on\", metadata={'source': '/home/chirayu.tripathi/hackathon/verizon_100.txt'}),\n",
       "  Document(page_content='Magical. Get it for as low as $4/mo,when you buy select iPhone.With select tablet trade-in. Buy Shop Devices Accessories Plans Home Internet & TV Deals TracFone Top Device Brands Samsung Apple Motorola Google Amazon Support Support overview Return policy Contact us Community Forums Sign in Download My Verizon App Lifeline Accessibility Check network status About Verizon About us Careers News Responsibility Verizon Innovative Learning Consumer info Articles Brochures Most Popular Apple iPhone 15', metadata={'source': '/home/chirayu.tripathi/hackathon/verizon_101.txt'}),\n",
       "  Document(page_content='Magical. Get it for as low as $4/mo,when you buy select iPhone.With select tablet trade-in. Buy Shop Devices Accessories Plans Home Internet & TV Deals TracFone Top Device Brands Samsung Apple Motorola Google Amazon Support Support overview Return policy Contact us Community Forums Sign in Download My Verizon App Lifeline Accessibility Check network status About Verizon About us Careers News Responsibility Verizon Innovative Learning Consumer info Articles Brochures Most Popular Apple iPhone 15', metadata={'source': '/home/chirayu.tripathi/hackathon/verizon_100.txt'})]}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_result = qa_bot()\n",
    "response = qa_result({'query': 'what are the deals on iphones?'})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c939a68-2ab9-4b0d-b0ac-f0cdb930acc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa_bot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qa_result \u001b[38;5;241m=\u001b[39m \u001b[43mqa_bot\u001b[49m()\n\u001b[1;32m      2\u001b[0m response \u001b[38;5;241m=\u001b[39m qa_result({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDo you provide iphones cases?\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      3\u001b[0m response\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qa_bot' is not defined"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9549c9eed76f44d0bb0af0ead3b7e1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "qa_result = qa_bot()\n",
    "response = qa_result({'query': 'Do you provide iphones cases?'})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f3a6a05-1c20-4025-aaa6-b57082817748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you provide iphones cases?',\n",
       " 'result': 'I am sorry, I do not have access to the current sale information. However, you can check out our website for the latest deals on cases and chargers for iPhones. Here is a link to our website where you can find more information: <https://www.verizon.com/shop/accessories/iphone-cases>',\n",
       " 'source_documents': [Document(page_content='Sale: Deals on Cases, Chargers, More | Verizon Accessibility Resource Center Skip to main content Personal Business Stores Español Shop Shop Shop Close Shop Shop all Deals Deals Deals Shop all deals Free phones My offers Smartphones Fios Home Internet Bring your own device Accessories Refer a Friend Refer a Friend Devices Devices Devices Smartphones 5G phones Certified pre-owned phones Featured smartphones Featured smartphones Featured smartphones Apple iPhone 15 Pro Apple iPhone 15 Samsung', metadata={'source': '/home/chirayu.tripathi/hackathon/verizon_101.txt'}),\n",
       "  Document(page_content='Accessories: Chargers, Cases & More | Verizon Accessibility Resource Center Skip to main content Personal Business Stores Español Shop Shop Shop Close Shop Shop all Deals Deals Deals Shop all deals Free phones My offers Smartphones Fios Home Internet Bring your own device Accessories Refer a Friend Refer a Friend Devices Devices Devices Smartphones 5G phones Certified pre-owned phones Featured smartphones Featured smartphones Featured smartphones Apple iPhone 15 Pro Apple iPhone 15 Samsung', metadata={'source': '/home/chirayu.tripathi/hackathon/verizon_101.txt'})]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b7d4f342-10bf-4ea8-b7aa-1362b3988527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-15 13:27:29 - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35d2c9bb7624b6e8bea78367d5355c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "qa_result = qa_bot()\n",
    "response = qa_result({'query': 'How to access my mailbox, if I am not at home?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6daff031-ad33-4956-9a2f-e6538b5b9f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How to access my mailbox, if I am not at home?',\n",
       " 'result': 'To access your mailbox when away from home: 1. Dial your Access Number, with area code when necessary. 2. Wait for an answer, then press # 3. Enter your mailbox number, (your 7 or 10 digit home telephone number depending on your area). 4. Enter your Passcode to reach the Home Voice Mail Main Menu.',\n",
       " 'source_documents': [Document(page_content='mailbox parameters. Once the message limit has been reached, you cannot receive new messages until you erase some of your stored messages. Accessing Your Mailbox To listen to your messages or to access other Home Voice Mail options, you will first need to dial into your mailbox. To access your mailbox from your home telephone: 1. Dial your Access Number. 2. Enter your Passcode to reach the Home Voice Mail Main Menu. To access your mailbox when away from home: 1. Dial your Access Number, with', metadata={'source': '/home/chirayu.tripathi/hackathon/north_hvm_ug_h2069.pdf', 'page': 4}),\n",
       "  Document(page_content='away from home: 1. Dial your Access Number, with area code when necessary. 2. Wait for an answer, then press # 3. Enter your mailbox number, (your 7 or 10 digit home telephone number depending on your area). 4. Enter your Passcode to reach the Home Voice Mail Main Menu. Listening To Your Messages Each message you retrieve is marked with the day and time it was received. For example, your message will be marked: “Received Monday, June 22, at 1:23 p.m.” You will then hear the recorded message.', metadata={'source': '/home/chirayu.tripathi/hackathon/north_hvm_ug_h2069.pdf', 'page': 4}),\n",
       "  Document(page_content='How to listen to your messages: 1. When you access your mailbox, the system will tell you how many messages you have and which other mailboxes have messages. 2. Press 1 from the Main Menu to hear your messages. 3. For message playback options, refer to “Listening to Your Messages.” 4. To access more than one mailbox on a single call, press * at the Main Menu. 5. Enter the passcode for the mailbox you wish to access. Deleting a Multiple Mailbox: The host can delete any of the mailboxes created.', metadata={'source': '/home/chirayu.tripathi/hackathon/north_hvm_ug_h2069.pdf', 'page': 8})]}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b278c98-d746-4c0d-a064-6d7c3a6b828e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://8be408bbc4d8fe746b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8be408bbc4d8fe746b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae23db7debc4dd98ad0151fb118b39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "gr.ChatInterface(bot.final_result).launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13e343-4222-48f9-ae77-c11ac98a6886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
